{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from models.unet.unet import UNetModelWrapper\n",
    "from models.unet import UNetModel\n",
    "from flow_matching.models import OTFM\n",
    "from torchdyn.core import NeuralODE\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Lipman et al. 2023, we use a MLP with 5-layers of 512 neurons for the 2D examples and the UNet architecture from Dhariwal & Nichol (2021) for the images. \n",
    "\n",
    "We generate results and compare the resutls for the models FM-OT and FM-Diffusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Checkboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by implemeting the flow matching and applying it to the CIFAR10 (Krizhevsky et al., 2009) dataset. As in Lipman et al., 2023, we evaluate likelihood and samples from the model using dopri5 (Dormand & Prince, 1980)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_channel = 128\n",
    "num_workers = 4\n",
    "lr = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR10(\n",
    "    root=\"./data_cifar10\",\n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_model = UNetModelWrapper(\n",
    "    dim=(3, 32, 32),\n",
    "    num_res_blocks=2,\n",
    "    num_channels=num_channel,\n",
    "    channel_mult=[1, 2, 2, 2],\n",
    "    num_heads=4,\n",
    "    num_head_channels=64,\n",
    "    attention_resolutions=\"16\",\n",
    "    dropout=0.1,\n",
    ").to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 32, 32])\n",
      "torch.Size([128, 32])\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "optmizer = torch.optim.Adam(net_model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "otfm = OTFM()\n",
    "sigma_min = 0.1\n",
    "n_epochs = 2\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    net_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch, _ in dataloader:\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        x_0 = torch.randn_like(batch).to(device)\n",
    "\n",
    "        x_1 = batch\n",
    "\n",
    "        t = torch.rand(len(batch), 3, 32, 32).to(device)\n",
    "        \n",
    "        x_t = otfm.compute_x_t(x_0, x_1, sigma_min)\n",
    "        dx_t = otfm.compute_dx_t(x_0, x_1, sigma_min, t)\n",
    "        \n",
    "        optmizer.zero_grad()\n",
    "        \n",
    "        loss = loss_fn(net_model(t, x_t), dx_t)\n",
    "        \n",
    "        loss.backward()        \n",
    "        optmizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {running_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow_matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
